{"Nomor": 65749, "Judul": "IMAGE CAPTIONING DENGAN TEXT AUGMENTATION DAN TRANSFORMER STUDI KASUS: DATA PARIWISATA", "Abstrak": "Pariwisata Indonesia memiliki banyak potensi karena berkaitan dengan alam dan\nbudaya sangat beragam yang dapat dikembangkan menjadi destinasi pariwisata.\nDengan penambahan deskripsi secara otomatis dapat digunakan dalam suatu\naplikasi untuk menyarankan tempat yang ingin dikunjungi. Image captioning\nmerupakan suatu task yang berkaitan dengan pembangkitan deskripsi gambar\nsecara otomatis. Perkembangan image captioning ini berlanjut dengan\ndikembangkannya model berbasis attention. Penelitian Xu dkk. (2015)\nmengembangkan model CNN-LSTM dengan menambahkan attention didalamnya.\nPenelitian tentang image captioning pada domain pariwisata Indonesia sudah\npernah dilakukan oleh Fudholi dkk. (2021). Penelitian tersebut juga menggunakan\narsitektur CNN-LSTM dengan attention seperti penelitian Xu dkk. (2015). Teknik\nyang dikembangkan pada penelitian tersebut adalah mengganti algoritma untuk\nfeature extraction yaitu VGG16 dengan algoritma feature extraction yang lebih\nbaru yaitu EfficientNet.\nPenelitian sebelumnya dari Fudholi dkk. (2021) masih menggunakan model\nsequential untuk bagian language model. Hal tersebut dikarenakan model\nsequential memiliki permasalahan dalam long-range context dependencies yaitu\nketika kalimat sudah panjang model sequence akan sulit menangkap jika ada\nhubungan pada kata awal dan kata akhir. Permasalahan lain pada model sequential\nyaitu ketika memproses data perlu menunggu hasil kata perkata. Masalah lain yang\nmuncul pada image captioning dengan caption berbahasa Indonesia adalah low\nresource availability. Hal tersebut menyebabkan kurangnya keberagaman dalam\npembangunan caption. Keberagaman caption yang dihasilkan model adalah suatu\nyang penting karena caption yang dihasilkan menjadi tidak membosankan dengan\nmenggunakan kata-kata yang sama.\nPada tesis ini telah dilakukan penelitian tentang model image captioning berbasis\ntransformers untuk menyelesaikan permasalahan yang ada pada model sequential\nyaitu long-range context dependencies. Dengan adanya multi-head attention pada\nmodel transformers yang dapat menangkap hubungan antarkata dengan baik\nmeskipun posisi kata tersebut berjauhan sehingga masalah long-range context\ndependencies dapat diselesaikan. Masalah yang akan diselesaikan pada penelitian\nII\nini adalah permasalahan low resource availability pada data image captioning\nberbahasa Indonesia dapat diatasi dengan melakukan text augmentation. Text\naugmentation dapat menambahkan beberapa variasi caption dengan mengganti\nbeberapa kata dari suatu kalimat sehingga menambah beberapa kosakata baru yang\nmungkin akan muncul. Kalimat yang dibentuk dari text augmentation diharapkan\nmemiliki makna yang sama dengan kalimat sebelum dilakukan text augmentation.\nTeknik text augmentation yang digunakan pada penelitian ini ada dua yaitu dengan\nWord2Vec dan BERT.\nDari penelitian ini diperoleh penggunaan model image captioning berbasis\ntransformers dapat meningkatkan kinerja baik dari segi ketepatan prediksi dan\nkeberagaman caption yang dihasilkan dibandingkan model berbasis attention yang\ndigunakan pada penelitian sebelumnya. Dibandingkan dengan model attention,\nmodel transformers mendapatkan penambahan untuk skor CIDEr sebanyak 0.741\ndan peningkatan skor BLEU-4 sebanyak 0.079. Pada metrik keberagaman juga\nterjadi peningkatan dari kosakata meningkat 19% lebih banyak, dan pada metrik\nDiv-1 dan Div-2 mendapatkan peningkatan secara berturut-turut 0.09 dan 0.134.\nHal tersebut dikarenakan pada model transformers memiliki multi-head attention\nyang bisa mempelajari hubungan antarkata. Dengan hal tersebut sehingga\nmenyebabkan kinerja ketepatan dan keberagaman lebih baik dibanding model\nattention yang menggunakan model sequential yaitu GRU yang memiliki masalah\nlong-range context dependencies yang juga menyebabakan kata berulang\ndikarenakan hilangnya informasi.\nDari hasil eksperimen pada penelitian ini diperloleh text augmentation menurunkan\nkinerja dari segi ketepatan. Penurunan pada model attention sebesar 0.026 pada\nmetrik CIDEr, dan 0.002 pada metrik BLEU-4. Sementara itu, pada model\ntransformers mengalami penurunan nilai CIDEr sebesar 0.335 dan penurunan nilai\nBLEU-4 sebesar 0.054. Penurunan tersebut menunjukan dengan melakukan text\naugmentation belum bisa membuat model dapat memprediksi caption menjadi\nlebih akurat. Namun penggunaan text augmentation dapat meningkatkan kinerja\nmodel dari segi keberagaman caption. Terbukti pada model attention dapat\nmeningkatkan kosakata 39% lebih banyak dan meningkatkan skor Div-2 sebanyak\n0.015. Model transformers text augmentation meningkatkan kosakata 35% lebih\nbanyak dan meningkatkan skor Div-2 sebanyak 0.008. Hal ini menunjukan bahwa\ntext augmentation dapat digunakan untuk task image captioning jika keberagaman\ncaption merupakan hal yang penting pada permasalahan tersebut.", "Daftar File": {}, "Penulis": "Marsa Thoriq Ahmada [23521045]", "Kontributor / Dosen Pembimbing": ["Dr. techn. Saiful Akbar, S.T., M.T."], "Jenis Koleksi": "Tesis", "Penerbit": "Informatika", "Fakultas": "Sekolah Teknik Elektro dan Informatika", "Subjek": "", "Kata Kunci": "image captioning, transformers, attention, text augmentation, BERT, Word2Vec.", "Sumber": "", "Staf Input/Edit": "Dessy Rondang Monaomi", "File": "0 file", "Tanggal Input": "24 Jun 2022"}