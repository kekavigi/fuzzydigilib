{"Nomor": 66555, "Judul": "PEMBANGKITAN ABSTRACT MEANING REPRESENTATION LINTAS BAHASA DARI KALIMAT  BERBAHASA INDONESIA", "Abstrak": "Abstract Meaning Representation (AMR) merupakan salah satu cara untuk\nmerepresentasikan semantik dari suatu kalimat. Pembangkit AMR untuk Bahasa\nIndonesia telah dikembangkan dengan pendekatan pembelajaran mesin\nmenggunakan XGBoost dan dependency parsing, namun masih memiliki\nketerbatasan dalam variasi konsep dan relasi yang dapat direpresentasikan dan\nukuran dataset yang relatif kecil. Pada penelitian ini dibangun model pembangkit\nAMR cross-lingual, yaitu pembangkitan graf AMR berbahasa Inggris dari kalimat\nberbahasa Indonesia, sebagai alternatif representasi semantik dari kalimat\nberbahasa Indonesia.\nDilakukan perancangan model pembangkit AMR cross-lingual berbasis Pointer\nGenerator Network untuk mengidentifikasi konsep, dan biaffine attention classifier\n\nuntuk mengidentifkasi relasi antar konsep tersebut. Karena dalam AMR cross-\nlingual model dilatih dengan menggunakan resource bahasa targetnya (dalam kasus\n\nini Inggris), maka dibangun korpus pelatihan dengan menggunakan 2 jenis dataset\nsilver. Dataset silver par yang berupa kalimat paralel dari PANL-BPPT\ndibangkitkan dengan pembangkit AMR Bahasa Inggris, dan dataset silver trans\nyang merupakan data latih dan validasi AMR 2.0 yang diterjemahkan dengan\nmenggunakan mesin translasi Opus-MT. Dalam penelitian ini dilakukan 3\npengujian, yaitu pengujian terhadap dataset silver yang digunakan, antara silver par\n\ndan silver trans. Kedua dilakukan pengujian terhadap skema pelatihan berupa zero-\nshot, bilingual, dan language-specific. Ketiga dilakukan pengujian terhadap\n\nalternatif multilingual word embedding yang digunakan, di antaranya adalah\nmBERT, XLM-R, dan mT5.\nBerdasarkan pengujian yang dilakukan, dataset silver trans memiliki kinerja yang\nterbaik, dengan skema pelatihan yang terbaik adalah skema bilingual dengan\nmenggunakan dataset silver bahasa Indonesia dan AMR 2.0 bahasa Inggris.\nMultilingual word embedding yang menghasilkan kinerja terbaik dalam penelitian\nini adalah mT5. Model ini memiliki kinerja yang setara dengan cross-lingual AMR\nuntuk bahasa Jerman, Italia, Spanyol, dan Cina. Tapi bila dibandingkan dengan\nbaseline translate and parse, model ini masih memiliki kinerja yang lebih rendah.\nAnalisis yang dilakukan menunjukkan bahwa pembangkit cross-lingual AMR\nkesulitan menangani kalimat sangat pendek terutama yang berupa entitas, kalimat\nyang tidak lengkap seperti tagar dan tanggal artikel, dan kalimat yang sangat\npanjang. Pengujian ekstrinsik juga dilakukan terhadap dataset parafrasa WReTE,\ndengan klasifikasi berdasar nilai smatch. Model ini menghasilkan kinerja yang\nlebih baik dibanding model berbasis Indo4B dan model yang serupa dengan\nmenggunakan AMR Indonesia. Namun masih memiliki kinerja lebih rendah\ndibandingkan model berbasis IndoBERT dan mBERT.", "Daftar File": {}, "Penulis": "Aditya Rachman Putra [23520032]", "Kontributor / Dosen Pembimbing": ["Dr. Masayu Leylia Khodra, S.T., M.T."], "Jenis Koleksi": "Tesis", "Penerbit": "Informatika", "Fakultas": "Sekolah Teknik Elektro dan Informatika", "Subjek": "", "Kata Kunci": "Cross Lingual, Abstract Meaning Representation, Dataset Silver, Stog, Parafrasa", "Sumber": "", "Staf Input/Edit": "Dessy Rondang Monaomi", "File": "0 file", "Tanggal Input": "28 Jun 2022"}