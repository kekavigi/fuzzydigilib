{"Nomor": 65286, "Judul": "STUDI IMPLEMENTASI REINFORCEMENT LEARNING UNTUK KONTROL KOORDINASI LAMPU LALU LINTAS DALAM MODEL JARINGAN JALAN SIMPANG JAMAK", "Abstrak": "Kemacetan lalu lintas memberikan kerugian besar di berbagai bidang. Salah satu penyebabnya adalah adanya konflik aliran kendaraan di persimpangan lalu lintas, yang diregulasikan dengan kontrol dari lampu lalu lintas. Perkembangan algoritma pembelajaran mesin, khususnya pembelajaran penguatan (reinforcement learning/RL), telah menunjukkan kemampuan untuk mempelajari model dengan kompleksitas tinggi sehingga berpotensi untuk diterapkan pada kontrol lampu lalu lintas skala besar secara koordinatif. Penelitian ini mengajukan penerapan teori mean-field pada RL yang mampu melakukan pembelajaran dengan berbagi parameter antaragen tetangga untuk meningkatkan koordinasi antarsimpang dalam algoritma Cooperative Double Q-learning (Co-DQL). Penelitian dilakukan di kawasan Jakarta Pusat yang jaringan jalan dan kondisi lalu lintasnya direplikasi pada simulator lalu lintas, VISSIM dan SUMO. VISSIM digunakan untuk melihat kondisi lalu lintas yang dihadapi dengan sistem kontrol Sydney Coordinated Adaptive Traffic System (SCATS). Algoritma Co-DQL diterapkan pada SUMO dan dibandingkan dengan algoritma RL lainnya, yaitu Deep Deterministic Policy Gradient (DDPG) dan Deep Q-learning (DQN); serta algoritma konvensional berupa Max-pressure (MP), Uniform, dan Webster\u2019s.\nBerdasarkan perbandingan waktu tempuh dan jumlah kendaraan sampai, simulasi menunjukkan bahwa algoritma DDPG, Uniform, dan Webster\u2019s menghasilkan performa yang lebih baik dibandingkan algoritma lainnya (diatas 40.000 kendaraan dan distribusi waktu tempuh kendaraan diatas 25.000 detik yang kecil). Hal tersebut terjadi karena algoritma-algoritma ini memiliki jenis aksi kontrol perubahan durasi siklus lampu yang lebih baik dari algoritma-algoritma dengan aksi kontrol perubahan fasa lampu adaptif. Aksi perubahan fasa tidak memiliki batasan dalam pergantian fasa sehingga pada jaringan yang mengalami bottleneck, suatu fasa bisa bertahan sangat lama. Hasil tersebut menunjukkan bahwa penerapan kontrol lalu lintas skala kota memerlukan penyesuaian tingkat lanjut untuk mendapatkan hasil memuaskan, khususnya pada model jaringan dan aksi kontrol yang diterapkan.", "Daftar File": {"ABSTRAK Gregory Sembiring Brahmana": "https://digilib.itb.ac.id/gdl/download/249385"}, "Penulis": "Gregory Sembiring Brahmana [13317001]", "Kontributor / Dosen Pembimbing": ["Ir. Endra Joelianto, Ph.D.", "Dr. Suprijanto, S.T., M.T.", "Dr. Vebi Nadhira, S.T., M.T.", "Dr.-Ing. Justin Pradipta, S.T., M.T."], "Jenis Koleksi": "Tugas Akhir", "Penerbit": "Teknik Fisika", "Fakultas": "Fakultas Teknologi Industri", "Subjek": "", "Kata Kunci": "kemacetan lalu lintas, kontrol lampu lalu lintas, koordinasi, reinforcement learning, Cooperative Double Q-learning, jumlah kendaraan sampai, waktu tempuh kendaraan", "Sumber": "", "Staf Input/Edit": "Irwan Sofiyan", "File": "1 file", "Tanggal Input": "22 Jun 2022"}