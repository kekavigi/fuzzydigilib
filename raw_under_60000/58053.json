{"Nomor": 58053, "Judul": "IMPLEMENTASI REINFORCEMENT LEARNING DENGAN  PENDEKATAN KOMPUTASI KUANTUM", "Abstrak": "Pada dasarnya reinforcement learning menerapkan prinsip trial dan error\nsehingga jenis pembelajaran ini membutuhkan waktu yang sangat lama untuk \ndapat menyelesaikan masalah. Selain itu berbeda dengan jenis pembelajaran \nlainnya, terdapat sebuah tantangan pada reinforcement learning yaitu adanya \ntrade off antara eksplorasi dan eksploitasi. Di sisi lain peneliti menemukan bahwa \npenerapan komputasi kuantum dapat mempercepat komputasi pada beragam \nmasalah secara kuadratik atau bahkan eksponensial. Sehingga peniliti mulai \nmenggunakan komputasi kuantum pada bidang pembelajaran mesin termasuk \npada reinforcement learning.\nPenelitian sebelumnya oleh Dong, dkk. (2008) menyelesaikan reinforcement \nlearning dengan metode tabular dan pemilihan aksi yang terinspirasi dari \nalgoritma kuantum, yaitu iterasi Grover. Penelitian ini menunjukkan bahwa \npenggunaan komputasi kuantum dapat menyeimbangkan trade off antara \neksplorasi dan eksploitasi. Namun penggunaan metode tabular tentunya membuat \nmetode ini tidak scalable. Penelitian lain yang dilakukan oleh Chen, dkk. (2019) \nmenyelesaikan reinforcement learning dengan metode aproksimasi menggunakan \nVariational Quantum Circuit (VQC). Namun penelitian ini lebih berfokus pada \npenggunaan parameter dan memori yang jauh lebih sedikit dibanding pada metode \nreinforcement learning klasik. Untuk mengisi kekurangan satu sama lain dari \nkedua metode tersebut, penelitian tesis ini pada dasarnya menggabungkan metode \nyang diusulkan oleh Dong, dkk. (2008) dan Chen, dkk. (2019) dengan beberapa \nmodifikasi.\nPada penelitian tesis ini dilakukan perbandingan antara kinerja dari metode yang \ndiusulkan pada tesis ini, kinerja dari metode yang diusulkan oleh Dong, dkk. \n(2008), metode yang diusulkan oleh Chen, dkk. (2019) dan metode reinforcement \nlearning klasik, yaitu algoritma DQN yang diimplementasi oleh Stable Baseline. \nPerbandingan tersebut dilakukan pada lingkungan frozen lake yang dikembangkan \noleh Gym OpenAI. Pada lingkungan frozen lake dengan peta berukuran 4x4, \nkinerja terbaik didapatkan dari metode Grover, kinerja terbaik kedua didapatkan \ndari metode yang diusulkan pada tesis ini. Sebaliknya pada lingkungan yang lebih \nbesar, yaitu peta berukuran 8x8 secara umum metode yang diusulkan pada tesis \nini memberikan kinerja terbaik atau dengan kata lain metode tersebut lebih \nii\nscalable. Baik pada peta berukuran 4x4 maupun peta berukuran 8x8, kinerja dari \nmetode VQC dan RL klasik secara umum lebih buruk dibanding kinerja dari \nmetode yang diusulkan. Hasil pengujian juga menunjukkan bahwa metode yang \ndiusulkan berhasil membuat agen melakukan eksplorasi dengan baik.\nDibandingkan dari segi waktu, metode Grover dan RL klasik membutuhkan \nwaktu yang lebih singkat dari metode yang diusulkan pada tesis ini. Namun \nmetode yang diusulkan membutuhkan waktu yang lebih singkat dari metode \nVQC. Dibandingkan dari segi konsumsi memori atau parameter, metode Grover \nmembutuhkan penyimpanan sebanyak N dimana N adalah jumlah anggota ruang \nstate dan metode RL klasik membutuhkan parameter sebanyak 64 x (N + 68).\nSedangkan parameter untuk metode yang diusulkan pada tesis ini dan metode \nVQC hanya membutuhkan parameter sebanyak 3 log N. Namun komputasi dari \nmetode yang diusulkan sedikit lebih kompleks dari metode VQC karena pada \ndasarnya metode yang diusulkan merupakan gabungan dari metode Grover dan \nmetode VQC sehingga membutuhkan lebih banyak qubit.", "Daftar File": {}, "Penulis": "Hani'ah Wafa [23520008]", "Kontributor / Dosen Pembimbing": ["Dr. Judhi Santoso, M.Sc."], "Jenis Koleksi": "Tesis", "Penerbit": "Informatika", "Fakultas": "Sekolah Teknik Elektro dan Informatika", "Subjek": "", "Kata Kunci": "reinforcement learning, komputasi kuantum, iterasi Grover, VQC,  frozen lake", "Sumber": "", "Staf Input/Edit": "karya", "File": "0 file", "Tanggal Input": "30 Agu 2021"}