{"Nomor": 73149, "Judul": "ALGORITMA ROBUST PERENCANA JALUR UNTUK LOKALISASI TARGET MULTI-AGENT PADA LINGKUNGAN YANG TIDAK DIKETAHUI", "Abstrak": "Penelitian ini mengusulkan sebuah pendekatan baru untuk meningkatkan robustness dari algoritma perencana jalur berbasiskan received signal strength (RSS) dengan mendefinisikan beberapa variabel sebagai state dari Q-learning. Secara umum, terdapat dua pendekatan untuk mendefinisikan state Q-learning pada permasalahan lokalisasi target berbasis RSS, yang mana keduanya hanya menggunakan satu variabel sebagai state Q-learning. Salah satu pendekatan tersebut berpotensi sulit untuk mencapai konvergensi. Sementara pendekatan yang lain berdasarkan asumsi yang tidak realistis dan bertentangan dengan karakteristik propagasi gelombang radio-frequency (RF). Dalam penelitian ini, akan dibuktikan bahwa jika asumsi tersebut tidak terpenuhi, kinerja metode yang diusulkan oleh penelitian lain tidak akan mampu konvergen. Selain itu, pada penelitian ini diusulkan pendekatan baru dengan menggunakan dua variabel sebagai state Q-learning. Pendekatan tersebut terbukti mampu mengungguli pendekatan yang hanya menggunakan satu variabel sebagai state Q-learning dalam hal kecepatan untuk mencapai konvergensi dan robustness.\nSelain itu, penelitian ini juga mengusulkan penggunaan distribusi Boltzmann untuk menggantikan ????????????????????????????? yang biasa digunakan sebagai metode eksplorasi pada penelitian lokalisasi target berbasiskan RSS. Hal ini bertujuan untuk mempercepat proses pembelajaran algoritma sehingga algoritma tidak memerlukan banyak episode pelatihan untuk dapat mencapai konvergensi. Hasil simulasi menunjukkan bahwa pengggunaan distribusi Boltzmann dapat mengurangi jumlah steps yang dibutuhkan oleh agent untuk mencapai target hingga 70% pada sepuluh episode pelatihan pertama.\nTerakhir, penelitian ini mencoba menyelesaikan permasalahan lokalisasi target berbasiskan RSS menggunakan pendekatan cooperative multi-agent. Pada pendekatan yang dilakukan, diusulkan metode penggabungan Q-table yang dimiliki oleh setiap agent dengan tetap memprioritaskan Q-value milik agent tersebut. Hasil simulasi menunjukkan bahwa penggunaan algoritma ini dapat mengurangi jumlah\nsteps hingga 18% dibandingkan dengan independent learners pada sepuluh episode pertama pelatihan.\nKata kunci: RSS, Q-learning, distribusi Boltzmann, independent learners, cooperative multi-agent", "Daftar File": {}, "Penulis": "Axel Dawne [13319076]", "Kontributor / Dosen Pembimbing": ["Prof. Dr. Ing. Ir. Yul Yunazwin, M.Sc., DIC.", "Ayu Gareta Risangtuni, S.T, M.T."], "Jenis Koleksi": "Tugas Akhir", "Penerbit": "Teknik Fisika", "Fakultas": "Fakultas Teknologi Industri", "Subjek": "", "Kata Kunci": "RSS, Q-learning, distribusi Boltzmann, independent learners, cooperative multi-agent", "Sumber": "", "Staf Input/Edit": "Irwan Sofiyan", "File": "1 file", "Tanggal Input": "15 Jun 2023"}